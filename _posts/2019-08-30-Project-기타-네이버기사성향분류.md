---
layout: post
title:  "크롤링 데이터 & Word2Vec 기반, 뉴스 성향 분류"
subtitle:   "크롤링 데이터 & Word2Vec 기반, 뉴스 성향 분류"
categories: Project
tags: etc
comments: true
---

## 데이터를 특정 2개 사이트에서 크롤링 하고, 이를 Word2Vec 모델을 기반으로 

## 네이버에 작성된 뉴스가 어느 성향으로 분류 되는지 개발한 모델이다.

<br/>

## 1. Mini Project - 뉴스 성향 분류 모델

  - Member : 김경록 외 4명

  - Status : Complete

  - 사용언어 : python 
  
  - 핵심 라이브러리 : BeautifulSoup, selenium, konlpy, sklearn, LIME

## 2. Why

네이버에 게재된 다양한 언론사 뉴스들은 

언어적 표현 방식, 주제 키워드 등에 따라 특정 성향을 띨 수 있습니다. 

본 프로젝트는 이 성향을 모델링하고, 어떤 기사 표현이 성향에 영향을 미치는지를 분석하는 것이 목표였습니다. 

## 3. Data

특정 2개 뉴스 사이트에서 Python 크롤링으로 약 1,000개 기사 수집 (A 단체 25500개, B 단체 25500개)

주요 텍스트 필드는 기사 제목과 본문

## 4. 분석 방법

(a). Data Crawling

	- Selenium 및 BeautifulSoup를 사용하여 사이트 별 뉴스 기사 수집
    - 수집한 텍스트에서 본문만 정제하여 분석에 사용
    - 불용어, 날짜 등 의미없는 단어에 대해서는 제거 작업 수행


(b). 명사 추출 패키지 비교 작업

	- Konlpy를 이용하여서 명사적인 부분만 가져오는 것을 목표
	- Okt (Open korea text), Hannanum, Kkma (Kind Korean Morpheme Analyzer), komoran

	  --> 명사가 중복되지 않고, 핵심적인 명사들만 최대한 가져오는 것을 목표로 함.
      
      명사 추출에 대해서 샘플링 진행 후, Okt 모델을 선택함.

      (Hannanum : 명사가 아닌 부분도 추출됨. / Kkma : 명사가 중복되게 추출 됨
      
      komoran : Okt와 가장 비슷하였지만 줄임말 등에 대해서 조금 약한 모습을 보임)

(c). 벡터화 (TF-IDF vs Word2Vec 비교)

	- gensim의 Word2Vec 모델로도 문서 임베딩 시도하였으나, 실험 결과 및 해석력 측면에서 TF-IDF 방식으로 최종 선택
    - TF-IDF는 각 문서에서 중요 단어의 가중치를 부여하며, 희소하지만 직관적 해석이 가능
    - Word2Vec은 밀집 벡터 구조로 일반화에는 강점이 있으나, 단어별 영향도 파악이 어려운 점에서 제한적임

(d). 분류 모델 학습

	- 로지스틱 회귀(Logistic Regression), LightGBM 등 비교 실험
	- 최종적으로는 TF-IDF + Logistic Regression 조합이 가장 높은 일반화 성능을 보여 최종 채택
	- Accuracy 약 95% 수준 달성
	- cf. 단 Accuracy는 각 단체의 데이터를 Train : Test (8:2) 로 해서 진행  + 10-Fold

		
*[github private link](https://github.com/bluemumin/nlp_korea_university_education_ver1)*