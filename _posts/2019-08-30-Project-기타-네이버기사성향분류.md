---
layout: post
title:  "크롤링 데이터 & NLP 기반, 뉴스 성향 분류"
subtitle:   "크롤링 데이터 & NLP 기반, 뉴스 성향 분류"
categories: Project
tags: etc
comments: true
---

## 네이버 작성 뉴스의 성향 분류 모델 개발 프로젝트이다.

<br/>

## 1. Mini Project - 뉴스 성향 분류 모델

  - Member : 김경록 외 4명

  - Status : Complete

  - 사용언어 : python 
  
  - 핵심 라이브러리 : BeautifulSoup, selenium, konlpy, sklearn, LIME

<br/>

## 2. Why

네이버에 게재된 다양한 언론사 뉴스들은 

언어적 표현 방식, 주제 키워드 등에 따라 특정 성향을 띨 수 있습니다. 

본 프로젝트는 이 성향을 모델링하고, 어떤 기사 표현 및 방식이

성향 분류에 영향을 미치는지를 분석하는 것이 목표였습니다. 

<br/>

## 3. Data

특정 2개 사이트에서 Python 크롤링으로 수집 

(A 단체 25500개, B 단체 25500개)

주요 텍스트 필드는 기사 제목과 본문

<br/>

## 4. 분석 방법

(a). Data Crawling

	- Selenium 및 BeautifulSoup를 사용하여 사이트 별 뉴스 기사 수집
    - 수집한 텍스트에서 본문만 정제하여 분석에 사용
    - 불용어, 날짜 등 의미없는 단어에 대해서는 제거 작업 수행


(b). 명사 추출 패키지 비교 작업

	- Konlpy를 이용하여서 명사적인 부분만 가져오는 것을 목표
  
	- Okt (Open korea text), Hannanum, Kkma (Kind Korean Morpheme Analyzer), komoran

	  --> 명사가 중복되지 않고, 핵심적인 명사들만 최대한 가져오는 것을 목표로 함.
      
      명사 추출에 대해서 샘플링 진행 후, Okt 모델을 선택함.

      (Hannanum : 명사가 아닌 부분도 추출됨. / Kkma : 명사가 중복되게 추출 됨
      
      komoran : Okt와 가장 비슷하였지만 줄임말 등에 대해서 조금 약한 모습을 보임)

(c). 벡터화 (TF-IDF vs Word2Vec 비교)

	- gensim의 Word2Vec 모델로도 문서 임베딩 시도하였으나, 
    실험 결과 및 해석력 측면에서 TF-IDF 방식으로 최종 선택

    - TF-IDF는 각 문서에서 중요 단어의 가중치를 부여하며, 
      희소하지만 직관적 해석이 가능

    - Word2Vec은 밀집 벡터 구조로 일반화에는 강점이 있으나, 
      단어별 영향도 파악이 어려운 점에서 제한적임

(d). 분류 모델 학습

	- 로지스틱 회귀(Logistic Regression), LightGBM 등 비교 실험
  
	- 최종적으로는 TF-IDF + Logistic Regression 조합이 가장 높은 일반화 성능을 보여 최종 채택
  
	- Accuracy 약 95% 수준 달성
  
	- cf. 단 Accuracy는 각 단체의 데이터를 Train : Test (8:2) 로 해서 진행  + 10-Fold 과정 추가

<br/>

## 5. 경험 사항 & 한계

- Word2Vec, TF-IDF 등 단어 벡터화에 대한 지식 습득. 

- 분석/개발 프로젝트 진행 과정에 대한 전반적인 process 및
  
  개선 방향성에 대해서 습득 가능.

- 딥러닝에 대한 지식까지 활용하기에는 시간 부족으로 당시에 미 진행

<br/>

## 6. 최신 관점에서의 개선 방향 (2025 기준)

    - 사전학습 언어모델(BERT, KoBERT, KLUE-BERT 등) 도입: 
    
    TF-IDF는 문맥을 반영하지 못하므로, 
    
    사전학습 언어모델을 사용해 문맥 기반 임베딩을 활용하면 더 정교한 분류 가능

    - 파인튜닝(fine-tuning): 전체 모델을 재학습하기보다, 
  
      크롤링한 뉴스 텍스트에 일부 도메인 적응을 통해 성능 개선 가능

    - 성향 해석의 투명성: SHAP 등 모델 설명 도구를 통해 
  
      어떤 단어나 문장이 분류 결과에 영향을 주었는지 시각화 가능

    - 멀티태스크/멀티레이블 분류 확장: 
  
      A vs B 뿐만 아니라 뉴스의 감성, 주제 등을 동시에 
      
      분류할 수 있는 구조로 확장 가능

    - 타 프로젝트에서의 활용 가능성 : GPT 등 데이터를 크롤링 할 때,

      불필요한 데이터까지 다 크롤링하는 것이 아닌, 해당 모델 기반으로

      편향 기사, 민감성 주제 등으로 분류하여 1차적인 필터링 가능.

<br/>
		
*[github private link](https://github.com/bluemumin/nlp_korea_university_education_ver1)*